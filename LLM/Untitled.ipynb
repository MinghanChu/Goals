{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87be30b5",
   "metadata": {},
   "source": [
    "# Large language model （LLM）\n",
    "\n",
    "*LLM (Large Language Model) is a system that leverages advanced mathematical algorithms, vast data storage, and significant computational power to process human language as input, perform complex computations, and generate language-based outputs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e252f",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "## Gemini\n",
    "\n",
    "## Anthropic Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069da7bb",
   "metadata": {},
   "source": [
    "OpenAI (Generative pretrained transformer GPT) vs Anthropic vs MistralAI vs Meta vs Google vs xAI\n",
    "\n",
    "Machine Learning\n",
    "├── Supervised Learning\n",
    "│   ├── Linear Regression\n",
    "│   ├── Support Vector Machines (SVMs)\n",
    "│   └── Decision Trees and Random Forests\n",
    "├── Unsupervised Learning\n",
    "│   ├── Clustering Algorithms (e.g., K-means, DBSCAN)\n",
    "│   └── Principal Component Analysis (PCA)\n",
    "├── Reinforcement Learning\n",
    "│   └── Training AI agents (e.g., Chess, Go)\n",
    "├── Semi-Supervised Learning\n",
    "└── Traditional Neural Networks (Non-Deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccb83f",
   "metadata": {},
   "source": [
    "Artificial Intelligence (AI), machine learning, deep learning foundmental framework is neural network that mimics how human brain works (one of the type of neural network that most LLM employs is transformer) (which is the most advanced type of machine learning).\n",
    "\n",
    "Neural network contains trememdous amount of layers and numbers which are given as random numbers and being adjusted towards the predicted result as training goes. every node in the neural network needs mulitplication. GPT3 contains 60-80 billion nodes of the neural network\n",
    "\n",
    "Transformer is one type of neural networks. Transformer is a type of structure. Videos, photos, audios are processed by diffusion models, which are not based the transformer structure and belong to LLM. Transformer does not only include multiplications between nodes but \n",
    "\n",
    "\n",
    "LLM training is composed of three steps: 1. preTraining is the process to 2. fine tunning 3. reinforcement learning with human feedback. \n",
    "\n",
    "1. pretraining is the process to search as many resources from the website as possible and use these data to train the model. The model itself deliberately removes some information from the found data, then it attempts to fill the missing information or predicts the missing information. After prediction, it uses the correct answer to adjust the trained model parameters. \n",
    "\n",
    "2. fine tunning and reinforcement learning with human feedback are based on the pretrained model and required must less calculations. This process needs human inputs to further train the model. Different IT companies use different techniques towards the pretraining, fine tunning and reinforcement with human feedback. This results in strengths and drawbacks between LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
