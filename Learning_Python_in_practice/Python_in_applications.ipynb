{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55d8d97",
   "metadata": {},
   "source": [
    "## Configuration file (`xxx.yml`)\n",
    "### Example: Inputs to `load_elbow_flow` `case1.yml` in `CoFiLD` project\n",
    "\n",
    "$\\underline{\\textbf{Data paths & Loading}}$\n",
    "```\n",
    "data_path: /HOME/scw6dou/run/minghan/CoNFiLD/data/Case1/data.npy\n",
    "```\n",
    "- Path to the main dataset file (`.npy` format, likely a `NumPy` array) for Case 1. This file contains the flow field data used for `training/testing`.\n",
    "\n",
    "```\n",
    "load_data_fn: load_elbow_flow\n",
    "```\n",
    "\n",
    "- The function used to load the dataset. \n",
    "\n",
    "- `load_elbow_flow` Suggests it is specifically for flow simulations in an \"elbow\" (e.g., curved pipe flow).\n",
    "\n",
    "```\n",
    "coor_path: /HOME/scw6dou/run/minghan/CoNFiLD/data/Case1/coords.npy\n",
    "```\n",
    "\n",
    "- Path to a `NumPy` file containing spatial coordinates of the dataset (e.g., `x, y, z` locations of grid points).\n",
    "- Used for reconstructing spatially resolved fields.\n",
    "\n",
    "\n",
    "$\\underline{\\textbf{Saving & Checkpointing}}$\n",
    "\n",
    "```\n",
    "save_path: /HOME/scw6dou/run/minghan/CoNFiLD/save/t0\n",
    "```\n",
    "- Directory where trained models, logs, and outputs will be saved.\n",
    "- `save_every: 5`: The model will be saved every 5 epochs\n",
    "\n",
    "\n",
    "$\\underline{\\textbf{Data Processing & Normalization}}$\n",
    "\n",
    "\n",
    "```\n",
    "lumped_latent: True \n",
    "```\n",
    "- Suggests that the latent representation of the data is \"lumped\" into a lower-dimensional format.  \n",
    "- This can reduce memory requirements and improve training efficiency.\n",
    "\n",
    "```\n",
    "normalizer:\n",
    "    method: '-11'\n",
    "    dim: 0\n",
    "```\n",
    "- `method: -11` Specifies the normalization method.\n",
    "- `-11` might mean Min-Max normalization, scaling values between -1 and 1.\n",
    "\n",
    "- `dim:0`: Normalization is applied along dimension 0 (likely the time axis).\n",
    "\n",
    "$\\underline{\\textbf{Batching & Computational Setup}}$\n",
    "\n",
    "```\n",
    "batch_size: 64\n",
    "```\n",
    "\n",
    "- Number of training samples per batch\n",
    "\n",
    "```\n",
    "test_batch_size\n",
    "```\n",
    "- Number of test samples per batch (large since testing doesn't require backpropagation)\n",
    "\n",
    "```\n",
    "multiGPU:1\n",
    "```\n",
    "- Whether multiple GPUs are used (1 means enabled)\n",
    "\n",
    "```\n",
    "readin_data_shape: \"t N c\"\n",
    "```\n",
    "\n",
    "- The expected shape of input data: `t:` time steps; `N:` number of spatial points; `c:` number of flow variables (e.g., velocity components)\n",
    "- batch shape of data batches, same as `readin_data_shape`.\n",
    "\n",
    "```\n",
    "batch_shape: \"t N c\"\n",
    "```\n",
    "- The shape of data batches, same as `readin_data_shape`.\n",
    "\n",
    "$\\underline{\\textbf{Training Parameters}}$\n",
    "\n",
    "```\n",
    "hidden_size: 128\n",
    "```\n",
    "\n",
    "- The number of hidden units in the neural network layers\n",
    "\n",
    "```\n",
    "epochs: 100\n",
    "```\n",
    "\n",
    "- The total number of training epochs\n",
    "\n",
    "```\n",
    "loss_fn:MSELoss\n",
    "```\n",
    "\n",
    "- The loss function used: Mean Squared Error (MSE), which penalizes large deviation from the ground truth.\n",
    "\n",
    "```\n",
    "test_criteria:rMAE\n",
    "```\n",
    "\n",
    "- Metric used to evaluate test performance: Relative Mean Absolute Error (rMAE)\n",
    "\n",
    "\n",
    "$\\underline{\\textbf{Neural Flow (NF) Model Settings}}$\n",
    "\n",
    "```\n",
    "NF:\n",
    "  name: SIRENAutodecoder_film\n",
    "  num_hidden_layers: 10\n",
    "  out_features: 3\n",
    "  hidden_features: 128\n",
    "```\n",
    "\n",
    "- Specifies the architecture for the Neural Field model.\n",
    "- name: SIRENAutodecoder_film\n",
    "    - The model type.\n",
    "    - \"SIREN\" (Sinusoidal Representation Networks) suggests using `sin activation functions`, which help represent high-frequency details.\n",
    "    - \"Autodecoder\" indicates that it learns a compressed representation (latent space)\n",
    "    - \"FiLM\" (Feature-wise Linear Modulation) suggests adaptive feature scaling/modulation.\n",
    "- `num_hidden layers:10`\n",
    "    - The number of hidden layers in the neural network.\n",
    "\n",
    "- `out_features: 3`\n",
    "    - The number of output features, likely representing three velocity components (`Ux, Uy, Uz`).\n",
    "    \n",
    "- `hidden_features: 128`\n",
    "    - The number of hidden units per layer.\n",
    "\n",
    "$\\underline{\\textbf{Learning Rates}}$\n",
    "\n",
    "```\n",
    "lr:\n",
    "  nf: 1.e-4\n",
    "  latents: 1.e-5\n",
    "```\n",
    "\n",
    "- `lr`:\n",
    "    - learning rate settings for different components\n",
    "    - `nf:1.e-4`\n",
    "        - Learning rate for the Neural Field model (SIREN-based network).\n",
    "        - Lower values stabilize training and prevent divergence.\n",
    "\n",
    "- `latents:1.e-5`\n",
    "    - Learning rate for latent space representations (used for encoding flow features).\n",
    "    - Smaller than `nf`, likely because latent updates need to be more stable.\n",
    "\n",
    "$\\underline{\\textbf{Dimensionality}}$\n",
    "\n",
    "```\n",
    "dims: 2\n",
    "```\n",
    "    - Specifies that the model is working in 2D flow fields.\n",
    "\n",
    "$\\underline{\\textbf{Summary}}$\n",
    "\n",
    "The model is learning spatiotemporal flow fields from DNS or experimental data.\n",
    "\n",
    "- It uses Neural Fields (SIREN-based) to reconstruct the flow over time.\n",
    "- Data is normalized, batched, and processed in time-space format (t N c).\n",
    "- The model learns a latent representation and uses adaptive learning rates for stability.\n",
    "- Outputs include velocity components (Ux, Uy, Uz) over an extended time horizon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b10f0",
   "metadata": {},
   "source": [
    "### How Python utilizes configuration files\n",
    "\n",
    "In the **./ConditionalNeuralField/cnf/utils/readdata.py:** file\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "def load_elbow_flow(path):\n",
    "    return np.load(f\"{path}\")[1:]\n",
    "\n",
    "def load_channel_flow(\n",
    "    path,\n",
    "    t_start=0,\n",
    "    t_end=1200,\n",
    "    t_every=1,\n",
    "):\n",
    "    return np.load(f\"{path}\")[t_start:t_end:t_every]\n",
    "\n",
    "def load_periodic_hill_flow(path):\n",
    "    data = np.load(f\"{path}\")\n",
    "    return data\n",
    "\n",
    "def load_3d_flow(path):\n",
    "    data = np.load(f\"{path}\")\n",
    "    return data\n",
    "```\n",
    "where four utility functions are defined, which are called to load the dataset into memory. Among them `def load_elbow_flow(path):` appears first.\n",
    "\n",
    "$\\underline{\\textbf{Explanation}}$\n",
    "\n",
    "It defines a Python function named `load_elbow_flow`\n",
    "- This function takes one argument: path, which is likely a file path to the dataset.\n",
    "- The function is designed to load data related to elbow flow cases (e.g., flow through a bent pipe).\n",
    "- This suggests that `readdata.py` is **a utility script** for reading different datasets.\n",
    "- in the given configuration file: it gives\n",
    "    - data_path: /HOME/scw6dou/run/minghan/CoNFiLD/data/Case1/data.npy\n",
    "    - load_data_fn: load_elbow_flow\n",
    "- when the **training** script runs, it will call:\n",
    "    - load_elbow_flow(\"/HOME/scw6dou/run/minghan/CoNFiLD/data/Case1/data.npy\")\n",
    "    - Reads the file at `data_path` using `Numpy`\n",
    "    - Loads the dataset into memory\n",
    "    - Returns the processed data for training\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
